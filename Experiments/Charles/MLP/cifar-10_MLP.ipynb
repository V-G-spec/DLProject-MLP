{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charleslego/opt/anaconda3/envs/DL_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Weights already downloaded\n",
      "Load_state output <All keys matched successfully>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charleslego/opt/anaconda3/envs/DL_env/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on CIFAR-10: 94.09%\n",
      "Accuracy on permuted CIFAR-10: 31.30%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from models.networks import get_model\n",
    "from data_utils.data_stats import *\n",
    "\n",
    "\n",
    "dataset = 'cifar10'                 # One of cifar10, cifar100, stl10, imagenet or imagenet21\n",
    "architecture = 'B_12-Wi_1024'\n",
    "data_resolution = 32                # Resolution of data as it is stored\n",
    "crop_resolution = 64                # Resolution of fine-tuned model (64 for all models we provide)\n",
    "num_classes = CLASS_DICT[dataset]\n",
    "data_path = './beton/'\n",
    "eval_batch_size = 1024\n",
    "checkpoint = 'in21k_cifar10'        # This means you want the network pre-trained on ImageNet21k and finetuned on CIFAR10\n",
    "\n",
    "\n",
    "\n",
    "# Set device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---------- Load the CIFAR-10 test dataset -------------\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(64),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "#--------- Load the permuted dataset ----------\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset_dict, transform = None):\n",
    "        self.dataset_dict = dataset_dict\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset_dict)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.dataset_dict[index]\n",
    "        image = data['image']\n",
    "        if self.transform:\n",
    "            image = self.transform(data['image'])\n",
    "        label = data['label']\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Load the dataset dictionary\n",
    "loaded_dataset = torch.load('cifar10_permuted.pth')\n",
    "\n",
    "# Create an instance of the CustomDataset\n",
    "permuted_dataset = CustomDataset(loaded_dataset, transform = transform)\n",
    "permuted_loader = DataLoader(permuted_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "\n",
    "# ------------- Load the pretrained model ------------\n",
    "\n",
    "pretrained_model = get_model(architecture=architecture, resolution=crop_resolution, num_classes=CLASS_DICT[dataset],\n",
    "                  checkpoint='in21k_cifar10')\n",
    "pretrained_model = pretrained_model.to(device)\n",
    "pretrained_model.eval()\n",
    "\n",
    "# -----------calculate accuracies -----------\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "correct_predictions_permuted = 0\n",
    "total_samples_permuted = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        \n",
    "        inputs = torch.reshape(inputs, (inputs.shape[0], -1))\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = pretrained_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Update counts\n",
    "        total_samples += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    for inputs, labels in permuted_loader:\n",
    "        \n",
    "        inputs = torch.reshape(inputs, (inputs.shape[0], -1))\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = pretrained_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Update counts\n",
    "        total_samples_permuted += labels.size(0)\n",
    "        correct_predictions_permuted += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_samples\n",
    "print(f'Accuracy on CIFAR-10: {100 * accuracy:.2f}%')\n",
    "\n",
    "# Calculate accuracy on permuted dataset\n",
    "accuracy_permuted = correct_predictions_permuted / total_samples_permuted\n",
    "print(f'Accuracy on permuted CIFAR-10: {100 * accuracy_permuted:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Code for per class accuracy -------------\n",
    "\n",
    "# Initialize a dictionary to store per-class counts\n",
    "class_counts = {class_idx: {'correct': 0, 'total': 0} for class_idx in range(num_classes)}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "\n",
    "        inputs = torch.reshape(inputs, (inputs.shape[0], -1))\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = pretrained_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Update counts for each class\n",
    "        for class_idx in range(num_classes):\n",
    "            class_mask = labels == class_idx\n",
    "            class_total = class_mask.sum().item()\n",
    "            class_correct = (predicted[class_mask] == class_idx).sum().item()\n",
    "\n",
    "            class_counts[class_idx]['correct'] += class_correct\n",
    "            class_counts[class_idx]['total'] += class_total\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "per_class_accuracy = {class_idx: class_counts[class_idx]['correct'] / class_counts[class_idx]['total']\n",
    "                      for class_idx in range(num_classes)}\n",
    "\n",
    "\n",
    "# Print per-class accuracy\n",
    "for class_idx in range(num_classes):\n",
    "    print(f'Accuracy for class {class_idx}: {100 * per_class_accuracy[class_idx]:.2f}%')\n",
    "\n",
    "\n",
    "#0: airplanes, 1: cars, 2: birds, 3: cats, 4: deer, 5: dogs, 6: frogs, 7: horses, 8: ships, 9: trucks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
