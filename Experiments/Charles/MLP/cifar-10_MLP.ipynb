{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Weights already downloaded\n",
      "Load_state output <All keys matched successfully>\n",
      "Accuracy for class 0: 96.20%\n",
      "Accuracy for class 1: 94.60%\n",
      "Accuracy for class 2: 94.80%\n",
      "Accuracy for class 3: 86.80%\n",
      "Accuracy for class 4: 96.10%\n",
      "Accuracy for class 5: 88.20%\n",
      "Accuracy for class 6: 95.90%\n",
      "Accuracy for class 7: 95.20%\n",
      "Accuracy for class 8: 96.60%\n",
      "Accuracy for class 9: 96.50%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models.networks import get_model\n",
    "from data_utils.data_stats import *\n",
    "\n",
    "\n",
    "dataset = 'cifar10'                 # One of cifar10, cifar100, stl10, imagenet or imagenet21\n",
    "architecture = 'B_12-Wi_1024'\n",
    "data_resolution = 32                # Resolution of data as it is stored\n",
    "crop_resolution = 64                # Resolution of fine-tuned model (64 for all models we provide)\n",
    "num_classes = CLASS_DICT[dataset]\n",
    "data_path = './beton/'\n",
    "eval_batch_size = 1024\n",
    "checkpoint = 'in21k_cifar10'        # This means you want the network pre-trained on ImageNet21k and finetuned on CIFAR10\n",
    "\n",
    "\n",
    "\n",
    "# Set device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the transformation for the input data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(64),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "# Load the CIFAR-10 test dataset\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "# Load a pretrained ResNet model (you can choose a different model)\n",
    "pretrained_model = get_model(architecture=architecture, resolution=crop_resolution, num_classes=CLASS_DICT[dataset],\n",
    "                  checkpoint='in21k_cifar10')\n",
    "pretrained_model = pretrained_model.to(device)\n",
    "pretrained_model.eval()\n",
    "\n",
    "# Initialize a dictionary to store per-class counts\n",
    "class_counts = {class_idx: {'correct': 0, 'total': 0} for class_idx in range(num_classes)}\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "\n",
    "        inputs = torch.reshape(inputs, (inputs.shape[0], -1))\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = pretrained_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Update counts for each class\n",
    "        for class_idx in range(num_classes):\n",
    "            class_mask = labels == class_idx\n",
    "            class_total = class_mask.sum().item()\n",
    "            class_correct = (predicted[class_mask] == class_idx).sum().item()\n",
    "\n",
    "            class_counts[class_idx]['correct'] += class_correct\n",
    "            class_counts[class_idx]['total'] += class_total\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "per_class_accuracy = {class_idx: class_counts[class_idx]['correct'] / class_counts[class_idx]['total']\n",
    "                      for class_idx in range(num_classes)}\n",
    "\n",
    "\n",
    "# Print per-class accuracy\n",
    "for class_idx in range(num_classes):\n",
    "    print(f'Accuracy for class {class_idx}: {100 * per_class_accuracy[class_idx]:.2f}%')\n",
    "\n",
    "\n",
    "#0: airplanes, 1: cars, 2: birds, 3: cats, 4: deer, 5: dogs, 6: frogs, 7: horses, 8: ships, 9: trucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models.networks import get_model\n",
    "from data_utils.data_stats import *\n",
    "\n",
    "# ... (the rest of your imports and settings remain unchanged)\n",
    "\n",
    "# Initialize a dictionary to store per-class counts\n",
    "class_counts = {class_idx: {'correct': 0, 'total': 0} for class_idx in range(num_classes)}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "\n",
    "        inputs = torch.reshape(inputs, (inputs.shape[0], -1))\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = pretrained_model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Update counts for each class\n",
    "        for class_idx in range(num_classes):\n",
    "            class_mask = labels == class_idx\n",
    "            class_total = class_mask.sum().item()\n",
    "            class_correct = (predicted[class_mask] == class_idx).sum().item()\n",
    "\n",
    "            class_counts[class_idx]['correct'] += class_correct\n",
    "            class_counts[class_idx]['total'] += class_total\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "per_class_accuracy = {class_idx: class_counts[class_idx]['correct'] / class_counts[class_idx]['total']\n",
    "                      for class_idx in range(num_classes)}\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = correct_predictions / total_samples\n",
    "\n",
    "# Print per-class accuracy\n",
    "for class_idx in range(num_classes):\n",
    "    print(f'Accuracy for class {class_idx}: {100 * per_class_accuracy[class_idx]:.2f}%')\n",
    "\n",
    "# Print overall accuracy\n",
    "print(f'Overall accuracy on CIFAR-10: {100 * overall_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "8\n",
      "8\n",
      "0\n",
      "6\n",
      "6\n",
      "1\n",
      "6\n",
      "3\n",
      "1\n",
      "0\n",
      "9\n",
      "5\n",
      "7\n",
      "9\n",
      "8\n",
      "5\n",
      "7\n",
      "8\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(test_dataset[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charleslego/opt/anaconda3/envs/DL_env/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[3, 32, 32]' is invalid for input of size 12288",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     img_np \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      9\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(norm_01(img_np))\n\u001b[0;32m---> 11\u001b[0m \u001b[43mshow_im\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m, in \u001b[0;36mshow_im\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_im\u001b[39m(batch):\n\u001b[0;32m----> 7\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      8\u001b[0m     img_np \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      9\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(norm_01(img_np))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[3, 32, 32]' is invalid for input of size 12288"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def norm_01(array):\n",
    "    return(array-np.min(array))/(np.max(array)-np.min(array))\n",
    "\n",
    "def show_im(batch):\n",
    "    img = batch.reshape(3,32,32).permute(1,2,0)\n",
    "    img_np = img.detach().numpy()\n",
    "    plt.imshow(norm_01(img_np))\n",
    "\n",
    "show_im(test_dataset[12][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charleslego/opt/anaconda3/envs/DL_env/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset[12][0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
