{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your working directory\n",
    "import os\n",
    "os.chdir('/Location_of_src_folder')\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from data_utils.data_stats import *\n",
    "from utils.metrics import topk_acc, real_acc, AverageMeter\n",
    "from models.networks import get_model\n",
    "from torchvision import datasets, transforms\n",
    "_ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cifar10'                 # One of cifar10, cifar100, stl10, imagenet or imagenet21\n",
    "architecture = 'B_12-Wi_1024'\n",
    "data_resolution = 32                # Resolution of data as it is stored\n",
    "crop_resolution = 64                # Resolution of fine-tuned model (64 for all models we provide)\n",
    "num_classes = CLASS_DICT[dataset]\n",
    "data_path = './beton/'\n",
    "eval_batch_size = 100\n",
    "checkpoint = 'in21k_cifar10'        # This means you want the network pre-trained on ImageNet21k and finetuned on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights already downloaded\n",
      "Load_state output <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the model and specify the pre-trained weights\n",
    "mlp = get_model(architecture=architecture, resolution=crop_resolution, num_classes=CLASS_DICT[dataset],\n",
    "                  checkpoint='in21k_cifar10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attach hook to \"harvest\" last-layer activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts_mlp = {}\n",
    "\n",
    "def hook_mlp(module, input, output):\n",
    "    assert input[0].shape[1] == 1024\n",
    "    acts_mlp['act'] = (input[0].clone().detach().numpy())\n",
    "\n",
    "hook_mlp = mlp.linear_out.register_forward_hook(hook_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the train loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(64),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform = transform)\n",
    "loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Harvest\" the activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_acts_mlp = []\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model_mlp, loader):\n",
    "    model_mlp.eval()\n",
    "    total_acc_mlp, total_top5_mlp = AverageMeter(), AverageMeter()\n",
    "\n",
    "    for ims, targs in tqdm(loader, desc=\"Evaluation\"):\n",
    "        ims_flat = torch.reshape(ims, (ims.shape[0], -1))\n",
    "        preds_mlp = model_mlp(ims_flat)\n",
    "        all_acts_mlp.append(acts_mlp['act'])\n",
    "\n",
    "        if dataset != 'imagenet_real':\n",
    "            acc_mlp, top5_mlp = topk_acc(preds_mlp, targs, k=5, avg=True)\n",
    "        else:\n",
    "            acc_mlp = real_acc(preds_mlp, targs, k=5, avg=True)\n",
    "            top5_mlp = 0\n",
    "\n",
    "        total_acc_mlp.update(acc_mlp, ims_flat.shape[0])\n",
    "        total_top5_mlp.update(top5_mlp, ims_flat.shape[0])\n",
    "\n",
    "    return (\n",
    "        total_acc_mlp.get_avg(percentage=True),\n",
    "        total_top5_mlp.get_avg(percentage=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charleslego/my_documents/ETH/Classes/Sem3/Deep_learning/Project/src/interpret_MLP/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "/Users/charleslego/my_documents/ETH/Classes/Sem3/Deep_learning/Project/src/interpret_MLP/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "Evaluation: 100%|██████████| 100/100 [00:55<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy MLP:       94.0900\n",
      "Top 5 Train Accuracy MLP: 99.6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_acc_mlp, test_top5_mlp = test(mlp, loader)\n",
    "hook_mlp.remove()\n",
    "\n",
    "# Print all the stats\n",
    "print(\"Test Accuracy MLP:      \", \"{:.4f}\".format(test_acc_mlp))\n",
    "print(\"Top 5 Train Accuracy MLP:\", \"{:.4f}\".format(test_top5_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the collected activations to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mlp\n",
    "acts_mlp_np = np.concatenate(all_acts_mlp, axis=0)\n",
    "\n",
    "with h5py.File('acts_' + architecture + '_' + dataset + '_test_postskip.h5', 'w') as hf:\n",
    "    hf.create_dataset('activations', data=acts_mlp_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
